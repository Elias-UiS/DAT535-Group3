{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2233f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark is available!\n"
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import json\n",
    "import findspark\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "findspark.init()\n",
    "\n",
    "# PySpark imports\n",
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.functions import *\n",
    "    from pyspark.sql.types import *\n",
    "    pyspark_available = True\n",
    "    print(\"PySpark is available!\")\n",
    "except ImportError:\n",
    "    print(\"PySpark not found. Please install with: pip install pyspark\")\n",
    "    pyspark_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9638aab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ SparkSession created successfully!\n",
      "Spark Version: 3.5.0\n",
      "Application Name: Lab2-PySpark-Basics\n",
      "Master: local[*]\n",
      "Default Parallelism: 4\n"
     ]
    }
   ],
   "source": [
    "if pyspark_available:\n",
    "    # Create SparkSession with custom configuration\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Lab2-PySpark-Basics\") \\\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "        .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "        .config(\"spark.driver.memory\", \"2g\") \\\n",
    "        .config(\"spark.executor.memory\", \"1g\") \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "    # Set log level to reduce verbose output\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    \n",
    "    print(\"✓ SparkSession created successfully!\")\n",
    "    print(f\"Spark Version: {spark.version}\")\n",
    "    print(f\"Application Name: {spark.sparkContext.appName}\")\n",
    "    print(f\"Master: {spark.sparkContext.master}\")\n",
    "    \n",
    "    # Check available cores and memory\n",
    "    print(f\"Default Parallelism: {spark.sparkContext.defaultParallelism}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Cannot proceed without PySpark. Please install PySpark first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e0aef20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Bronze Layer: Raw Data Ingestion ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/12 13:16:57 WARN TaskSetManager: Stage 85 contains a task of very large size (1086 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bronze Layer Data (Raw with Metadata):\n",
      "+-------------------+----------+------------------+----------+--------------------------+-------------+------+-------------+---------------+---------------------+----------------+------------------------+--------------------+--------------+-----------------+---------------+-----------+-----------+---------------+-----------------+--------------------+-------+-------+---------+\n",
      "|Access_to_Resources|Attendance|Distance_from_Home|Exam_Score|Extracurricular_Activities|Family_Income|Gender|Hours_Studied|Internet_Access|Learning_Disabilities|Motivation_Level|Parental_Education_Level|Parental_Involvement|Peer_Influence|Physical_Activity|Previous_Scores|School_Type|Sleep_Hours|Teacher_Quality|Tutoring_Sessions|_ingestion_timestamp|_source|_status|_raw_data|\n",
      "+-------------------+----------+------------------+----------+--------------------------+-------------+------+-------------+---------------+---------------------+----------------+------------------------+--------------------+--------------+-----------------+---------------+-----------+-----------+---------------+-----------------+--------------------+-------+-------+---------+\n",
      "|High               |84        |Near              |67        |No                        |Low          |Male  |23           |Yes            |No                   |Low             |High School             |Low                 |Positive      |3                |73             |Public     |7          |Medium         |0                |1.7629534180419807E9|file   |valid  |NULL     |\n",
      "|Medium             |64        |Moderate          |61        |No                        |Medium       |Female|19           |Yes            |No                   |Low             |College                 |Low                 |Negative      |4                |59             |Public     |8          |Medium         |2                |1.7629534180420594E9|file   |valid  |NULL     |\n",
      "|Medium             |98        |Near              |74        |Yes                       |Medium       |Male  |24           |Yes            |No                   |Medium          |Postgraduate            |Medium              |Neutral       |4                |91             |Public     |7          |Medium         |2                |1.7629534180420654E9|file   |valid  |NULL     |\n",
      "|Medium             |89        |Moderate          |71        |Yes                       |Medium       |Male  |29           |Yes            |No                   |Medium          |High School             |Low                 |Negative      |4                |98             |Public     |8          |Medium         |1                |1.7629534180420845E9|file   |valid  |NULL     |\n",
      "|Medium             |92        |Near              |70        |Yes                       |Medium       |Female|19           |Yes            |No                   |Medium          |College                 |Medium              |Neutral       |4                |65             |Public     |6          |High           |3                |1.7629534180420895E9|file   |valid  |NULL     |\n",
      "|Medium             |88        |Near              |71        |Yes                       |Medium       |Male  |19           |Yes            |No                   |Medium          |Postgraduate            |Medium              |Positive      |3                |89             |Public     |8          |Medium         |3                |1.7629534180420935E9|file   |valid  |NULL     |\n",
      "|Low                |84        |Moderate          |67        |Yes                       |Low          |Male  |29           |Yes            |No                   |Low             |High School             |Medium              |Neutral       |2                |68             |Private    |7          |Medium         |1                |1.7629534180421226E9|file   |valid  |NULL     |\n",
      "|High               |78        |Far               |66        |Yes                       |High         |Male  |25           |Yes            |No                   |Medium          |High School             |Low                 |Negative      |2                |50             |Public     |6          |High           |1                |1.7629534180421562E9|file   |valid  |NULL     |\n",
      "|High               |94        |Near              |69        |No                        |Medium       |Male  |17           |Yes            |No                   |High            |College                 |Medium              |Neutral       |1                |80             |Private    |6          |Low            |0                |1.7629534180421612E9|file   |valid  |NULL     |\n",
      "|Medium             |98        |Moderate          |72        |Yes                       |High         |Male  |23           |Yes            |No                   |Medium          |High School             |Medium              |Positive      |5                |71             |Public     |8          |High           |0                |1.7629534180421653E9|file   |valid  |NULL     |\n",
      "|High               |80        |Moderate          |68        |No                        |Medium       |Male  |17           |No             |No                   |Medium          |College                 |Low                 |Neutral       |4                |88             |Private    |8          |High           |4                |1.7629534180421693E9|file   |valid  |NULL     |\n",
      "|High               |97        |Near              |71        |Yes                       |Low          |Male  |17           |Yes            |No                   |Low             |High School             |Medium              |Neutral       |2                |87             |Private    |6          |High           |2                |1.7629534180421746E9|file   |valid  |NULL     |\n",
      "|Medium             |83        |Near              |70        |Yes                       |Medium       |Male  |21           |Yes            |No                   |Low             |High School             |Medium              |Positive      |4                |97             |Public     |8          |Medium         |2                |1.762953418042179E9 |file   |valid  |NULL     |\n",
      "|Medium             |82        |Near              |66        |Yes                       |Medium       |Male  |9            |Yes            |No                   |Medium          |Postgraduate            |Medium              |Positive      |3                |72             |Private    |8          |Medium         |2                |1.762953418042183E9 |file   |valid  |NULL     |\n",
      "|High               |78        |Near              |65        |Yes                       |Low          |Male  |10           |Yes            |No                   |Medium          |Postgraduate            |Medium              |Neutral       |4                |74             |Private    |8          |Medium         |1                |1.7629534180421867E9|file   |valid  |NULL     |\n",
      "|Medium             |68        |Near              |64        |No                        |Medium       |Female|17           |Yes            |No                   |Medium          |High School             |Medium              |Positive      |4                |70             |Private    |8          |Medium         |2                |1.7629534180422204E9|file   |valid  |NULL     |\n",
      "|Low                |60        |Near              |60        |Yes                       |High         |Male  |14           |Yes            |No                   |Low             |College                 |Medium              |Positive      |3                |65             |Private    |10         |Medium         |0                |1.7629534180422244E9|file   |valid  |NULL     |\n",
      "|Medium             |70        |Near              |65        |Yes                       |Low          |Female|22           |Yes            |No                   |Medium          |High School             |Low                 |Neutral       |3                |82             |Public     |6          |High           |1                |1.7629534180422285E9|file   |valid  |NULL     |\n",
      "|Medium             |80        |Moderate          |67        |Yes                       |Low          |Female|15           |Yes            |No                   |Low             |College                 |Medium              |Positive      |2                |91             |Public     |9          |Medium         |3                |1.762953418042232E9 |file   |valid  |NULL     |\n",
      "|High               |75        |Near              |66        |Yes                       |Medium       |Male  |12           |Yes            |No                   |Medium          |College                 |Medium              |Positive      |4                |58             |Private    |7          |Medium         |3                |1.7629534180422359E9|file   |valid  |NULL     |\n",
      "+-------------------+----------+------------------+----------+--------------------------+-------------+------+-------------+---------------+---------------------+----------------+------------------------+--------------------+--------------+-----------------+---------------+-----------+-----------+---------------+-----------------+--------------------+-------+-------+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "Data Quality Metrics:\n",
      "Total records: 7322\n",
      "Valid records: 6892\n",
      "Parse errors: 430\n",
      "Success rate: 94.1%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "if pyspark_available:\n",
    "    print(\"=== Bronze Layer: Raw Data Ingestion ===\")\n",
    "\n",
    "    # File paths\n",
    "    file_path = \"./students_unstructured.json\"\n",
    "\n",
    "    # Convert to JSON array\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "\n",
    "    # Create RDD from raw JSON strings\n",
    "    raw_rdd = spark.sparkContext.parallelize(lines)\n",
    "\n",
    "    # Parse JSON and handle errors (Bronze layer pattern)\n",
    "    def parse_json_safe(json_str):\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            data['_ingestion_timestamp'] = time.time()\n",
    "            data['_source'] = 'file'\n",
    "            data['_status'] = 'valid'\n",
    "            return data\n",
    "        except:\n",
    "            return {\n",
    "                '_raw_data': json_str,\n",
    "                '_ingestion_timestamp': time.time(),\n",
    "                '_source': 'file',\n",
    "                '_status': 'parse_error'\n",
    "            }\n",
    "        \n",
    "    # Apply parsing\n",
    "    bronze_rdd = raw_rdd.map(parse_json_safe)\n",
    "    bronze_data = bronze_rdd.collect()\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    bronze_df = spark.createDataFrame(bronze_data)\n",
    "    \n",
    "    print(\"Bronze Layer Data (Raw with Metadata):\")\n",
    "    bronze_df.show(truncate=False)\n",
    "    \n",
    "    # Show data quality metrics\n",
    "    total_records = bronze_df.count()\n",
    "    valid_records = bronze_df.filter(col(\"_status\") == \"valid\").count()\n",
    "    error_records = bronze_df.filter(col(\"_status\") == \"parse_error\").count()\n",
    "    \n",
    "    print(f\"\\nData Quality Metrics:\")\n",
    "    print(f\"Total records: {total_records}\")\n",
    "    print(f\"Valid records: {valid_records}\")\n",
    "    print(f\"Parse errors: {error_records}\")\n",
    "    print(f\"Success rate: {(valid_records/total_records)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a9abab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Silver Layer: Cleaned and Standardized Data ===\n",
      "PythonRDD[260] at RDD at PythonRDD.scala:53\n",
      "PythonRDD[261] at RDD at PythonRDD.scala:53\n",
      "\n",
      "Average Exam_Score by School_Type:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/12 14:12:03 WARN TaskSetManager: Stage 114 contains a task of very large size (1086 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/11/12 14:12:04 WARN TaskSetManager: Stage 116 contains a task of very large size (1086 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Private: 67.26\n",
      "Public: 67.21\n",
      "Unknown: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/12 14:12:04 WARN TaskSetManager: Stage 117 contains a task of very large size (1086 KiB). The maximum recommended task size is 1000 KiB.\n",
      "25/11/12 14:12:04 WARN TaskSetManager: Stage 118 contains a task of very large size (1086 KiB). The maximum recommended task size is 1000 KiB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+------------------+----------+--------------------------+-------------+------+-------------+---------------+---------------------+----------------+------------------------+--------------------+--------------+-----------------+---------------+-----------+-----------+---------------+-----------------+--------------------+-------+-------+\n",
      "|Access_to_Resources|Attendance|Distance_from_Home|Exam_Score|Extracurricular_Activities|Family_Income|Gender|Hours_Studied|Internet_Access|Learning_Disabilities|Motivation_Level|Parental_Education_Level|Parental_Involvement|Peer_Influence|Physical_Activity|Previous_Scores|School_Type|Sleep_Hours|Teacher_Quality|Tutoring_Sessions|_ingestion_timestamp|_source|_status|\n",
      "+-------------------+----------+------------------+----------+--------------------------+-------------+------+-------------+---------------+---------------------+----------------+------------------------+--------------------+--------------+-----------------+---------------+-----------+-----------+---------------+-----------------+--------------------+-------+-------+\n",
      "|High               |84.0      |Near              |67.0      |No                        |Low          |Male  |23.0         |Yes            |No                   |Low             |High School             |Low                 |Positive      |3.0              |73.0           |Public     |7.0        |Medium         |0.0              |1.7629567245679345E9|file   |valid  |\n",
      "|Medium             |64.0      |Moderate          |61.0      |No                        |Medium       |Female|19.0         |Yes            |No                   |Low             |College                 |Low                 |Negative      |4.0              |59.0           |Public     |8.0        |Medium         |2.0              |1.762956724568004E9 |file   |valid  |\n",
      "|Medium             |98.0      |Near              |74.0      |Yes                       |Medium       |Male  |24.0         |Yes            |No                   |Medium          |Postgraduate            |Medium              |Neutral       |4.0              |91.0           |Public     |7.0        |Medium         |2.0              |1.7629567245680177E9|file   |valid  |\n",
      "|Medium             |89.0      |Moderate          |71.0      |Yes                       |Medium       |Male  |29.0         |Yes            |No                   |Medium          |High School             |Low                 |Negative      |4.0              |98.0           |Public     |8.0        |Medium         |1.0              |1.762956724568038E9 |file   |valid  |\n",
      "|Medium             |92.0      |Near              |70.0      |Yes                       |Medium       |Female|19.0         |Yes            |No                   |Medium          |College                 |Medium              |Neutral       |4.0              |65.0           |Public     |6.0        |High           |3.0              |1.7629567245680482E9|file   |valid  |\n",
      "+-------------------+----------+------------------+----------+--------------------------+-------------+------+-------------+---------------+---------------------+----------------+------------------------+--------------------+--------------+-----------------+---------------+-----------+-----------+---------------+-----------------+--------------------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "=== Silver Layer Data Quality ===\n",
      "+----------------+\n",
      "|Exam_Score_nulls|\n",
      "+----------------+\n",
      "|             430|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if pyspark_available:\n",
    "    print(\"=== Silver Layer: Cleaned and Standardized Data ===\")\n",
    "    \n",
    "    # Start with valid Bronze layer data\n",
    "    valid_bronze_df = bronze_df.rdd.filter(lambda row: row['_status'] == 'valid')\n",
    "\n",
    "    # Removes duplicated rows\n",
    "    dedup_rdd = valid_bronze_df.map(lambda r: (tuple(sorted(r.items())), r)) \\\n",
    "        .reduceByKey(lambda a, b: a) \\\n",
    "        .map(lambda kv: kv[1])\n",
    "    print(dedup_rdd)\n",
    "\n",
    "    # Silver layer transformations\n",
    "    def clean_and_cast(row):\n",
    "        row_dict = dict(row)  \n",
    "\n",
    "        # Numeric fields: \n",
    "        numeric_fields = [\"Hours_Studied\", \"Attendance\", \"Sleep_Hours\", \"Previous_Scores\",\n",
    "                        \"Tutoring_Sessions\", \"Physical_Activity\", \"Exam_Score\"]\n",
    "        \n",
    "        # Categorical fields: cast to string, replace missing with 'Unknown'\n",
    "        categorical_fields = [\"Parental_Involvement\", \"Access_to_Resources\", \"Extracurricular_Activities\",\n",
    "                            \"Motivation_Level\", \"Internet_Access\", \"Family_Income\", \"Teacher_Quality\",\n",
    "                            \"School_Type\", \"Peer_Influence\", \"Learning_Disabilities\", \n",
    "                            \"Parental_Education_Level\", \"Distance_from_Home\", \"Gender\"]\n",
    "        \n",
    "        # Cast to int and replace missing with 0\n",
    "        for field in numeric_fields:\n",
    "            val = row_dict.get(field)\n",
    "            row_dict[field] = int(val) if val not in [None, \"\"] else 0\n",
    "\n",
    "        # Cast to string, replace missing with 'Unknown'\\\n",
    "        for field in categorical_fields:\n",
    "            val = row_dict.get(field)\n",
    "            row_dict[field] = str(val).strip() if val not in [None, \"\"] else \"Unknown\"\n",
    "\n",
    "        return row_dict\n",
    "\n",
    "    # Apply cleaning + type casting\n",
    "    cleaned_rdd = dedup_rdd.map(clean_and_cast)\n",
    "\n",
    "    # Collect results\n",
    "    #cleaned_data = cleaned_rdd.collect()\n",
    "    print(cleaned_rdd)\n",
    "\n",
    "    # ---- Map clean function over RDD ----\n",
    "    silver_rdd = bronze_rdd.map(lambda r: clean_row(r))\n",
    "\n",
    "    # ---- Example aggregation: average Exam_Score by School_Type ----\n",
    "    school_scores = silver_rdd.map(lambda r: (r[\"School_Type\"], r[\"Exam_Score\"]))\n",
    "    school_totals = school_scores.mapValues(lambda s: (s, 1)) \\\n",
    "                                .reduceByKey(lambda a, b: (a[0]+b[0], a[1]+b[1]))\n",
    "    school_avg = school_totals.mapValues(lambda x: x[0]/x[1])\n",
    "\n",
    "    print(\"\\nAverage Exam_Score by School_Type:\")\n",
    "    for school, avg_score in school_avg.collect():\n",
    "        print(f\"{school}: {avg_score:.2f}\")\n",
    "\n",
    "    # ---- Optional: convert Silver RDD to DataFrame for downstream use ----\n",
    "    silver_df = spark.createDataFrame(silver_rdd)\n",
    "    silver_df.show(5, truncate=False)\n",
    "    \n",
    "    # Data validation and quality checks\n",
    "    print(\"=== Silver Layer Data Quality ===\")\n",
    "    \n",
    "    # Check for null values in critical fields\n",
    "    null_checks = silver_df.select([\n",
    "        F.count(when(col(c).isNull(), c)).alias(f\"{c}_nulls\") \n",
    "        for c in [\"Exam_Score\"]\n",
    "    ])\n",
    "    null_checks.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3ea141",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pyspark_available:\n",
    "    print(\"=== Gold Layer: Business Metrics and Analytics ===\")\n",
    "    \n",
    "    # User activity summary (Gold layer aggregation)\n",
    "    user_activity_gold = silver_df.groupBy(\"user_id\").agg(\n",
    "        F.count(\"*\").alias(\"total_events\"),\n",
    "        countDistinct(\"event\").alias(\"unique_events\"),\n",
    "        min(\"timestamp\").alias(\"first_activity\"),\n",
    "        max(\"timestamp\").alias(\"last_activity\"),\n",
    "        sum(\"amount\").alias(\"total_spent\"),\n",
    "        countDistinct(\"device\").alias(\"devices_used\")\n",
    "    ).withColumn(\"session_duration_minutes\", \n",
    "                 (unix_timestamp(\"last_activity\") - unix_timestamp(\"first_activity\")) / 60\n",
    "    )\n",
    "    \n",
    "    print(\"User Activity Summary (Gold Layer):\")\n",
    "    user_activity_gold.show()\n",
    "    \n",
    "    # Daily metrics rollup\n",
    "    daily_metrics_gold = silver_df.groupBy(\"event_date\").agg(\n",
    "        F.count(\"*\").alias(\"total_events\"),\n",
    "        countDistinct(\"user_id\").alias(\"unique_users\"),\n",
    "        sum(\"amount\").alias(\"daily_revenue\"),\n",
    "        avg(\"amount\").alias(\"avg_transaction\"),\n",
    "        F.count(when(col(\"event\") == \"purchase\", 1)).alias(\"purchases\"),\n",
    "        F.count(when(col(\"event\") == \"login\", 1)).alias(\"logins\"),\n",
    "        F.count(when(col(\"event\") == \"signup\", 1)).alias(\"signups\")\n",
    "    ).withColumn(\"conversion_rate\", \n",
    "                 round(col(\"purchases\") / col(\"unique_users\") * 100, 2)\n",
    "    )\n",
    "    \n",
    "    print(\"Daily Metrics Summary (Gold Layer):\")\n",
    "    daily_metrics_gold.show()\n",
    "    \n",
    "    # Hourly activity pattern\n",
    "    hourly_pattern_gold = silver_df.groupBy(\"event_hour\").agg(\n",
    "        F.count(\"*\").alias(\"events_count\"),\n",
    "        countDistinct(\"user_id\").alias(\"active_users\")\n",
    "    ).orderBy(\"event_hour\")\n",
    "    \n",
    "    print(\"Hourly Activity Pattern (Gold Layer):\")\n",
    "    hourly_pattern_gold.show()\n",
    "    \n",
    "    # Device preference analysis\n",
    "    device_analysis_gold = silver_df.groupBy(\"device\", \"event\").agg(\n",
    "        F.count(\"*\").alias(\"event_count\")\n",
    "    ).groupBy(\"device\").pivot(\"event\").sum(\"event_count\").fillna(0)\n",
    "    \n",
    "    print(\"Device Preference Analysis (Gold Layer):\")\n",
    "    device_analysis_gold.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
